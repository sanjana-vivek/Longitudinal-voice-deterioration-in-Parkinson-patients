{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Completely remove both packages and cached wheels\n",
        "!pip uninstall -y parselmouth praat-parselmouth googleads\n",
        "!pip cache purge\n",
        "!rm -rf /root/.cache/pip /usr/local/lib/python*/dist-packages/parselmouth* /usr/local/lib/python*/dist-packages/googleads*\n",
        "!pip install praat-parselmouth==0.4.3 --no-cache-dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMwC9r__VJBO",
        "outputId": "a014a45a-06a7-4c01-cfa4-5fd1b79064b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping parselmouth as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: praat-parselmouth 0.4.3\n",
            "Uninstalling praat-parselmouth-0.4.3:\n",
            "  Successfully uninstalled praat-parselmouth-0.4.3\n",
            "\u001b[33mWARNING: Skipping googleads as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFiles removed: 54 (3.0 MB)\n",
            "Collecting praat-parselmouth==0.4.3\n",
            "  Downloading praat_parselmouth-0.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from praat-parselmouth==0.4.3) (2.0.2)\n",
            "Downloading praat_parselmouth-0.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --upgrade pip setuptools wheel\n",
        "\n",
        "\n",
        "# Core dependencies\n",
        "!pip install --upgrade librosa soundfile pandas scipy scikit-learn matplotlib tqdm torch torchvision transformers keras tensorflow\n",
        "\n",
        "# Specialized scientific & signal libraries\n",
        "!pip install PyWavelets\n",
        "!pip install git+https://github.com/CSchoel/nolds.git\n",
        "!pip install git+https://github.com/kymatio/kymatio.git\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp_5Fj_aNBSY",
        "outputId": "356a6724-fb5e-48f3-b8ca-042aa868f807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.12/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from PyWavelets) (2.0.2)\n",
            "Collecting git+https://github.com/CSchoel/nolds.git\n",
            "  Cloning https://github.com/CSchoel/nolds.git to /tmp/pip-req-build-a4gpo_w7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/CSchoel/nolds.git /tmp/pip-req-build-a4gpo_w7\n",
            "  Resolved https://github.com/CSchoel/nolds.git to commit f121feebf6b2cbd67a8cb855bd0fe8c39add3ad9\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<3.0,>1.0 in /usr/local/lib/python3.12/dist-packages (from nolds==0.6.2) (2.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from nolds==0.6.2) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from nolds==0.6.2) (80.9.0)\n",
            "Collecting git+https://github.com/kymatio/kymatio.git\n",
            "  Cloning https://github.com/kymatio/kymatio.git to /tmp/pip-req-build-fyslrdl8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/kymatio/kymatio.git /tmp/pip-req-build-fyslrdl8\n",
            "  Resolved https://github.com/kymatio/kymatio.git to commit e1fe488657c03a0a9c48e727b61fb5eea7005d82\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from kymatio==0.4.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from kymatio==0.4.0.dev0) (1.16.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from kymatio==0.4.0.dev0) (1.4.4)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.12/dist-packages (from kymatio==0.4.0.dev0) (7.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kymatio==0.4.0.dev0) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvrnHhbOYeE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14377194-e311-4043-c8be-0c9ef9aba3ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m No available output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Failed to build 'googleads' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
            "\u001b[0mRunning on: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 578 .wav files\n",
            "\n",
            "📂 First 30 files in dataset:\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW20.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW13.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW10.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW15.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW1.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW14.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW21.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW18.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW6.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW2.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW12.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW16.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW19.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW11.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW4.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW17.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW5.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW9.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW8.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/LW/LW3.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/Tessi/ES11.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/Tessi/ES28.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/Tessi/ES12.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/Tessi/SI16.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/Tessi/SI19.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/Tessi/ES25.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/Tessi/ES17.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/Tessi/ES24.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/Tessi/ES26.wav\n",
            "/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset/Tessi/SI9.wav\n",
            "\n",
            "✅ All listed files exist.\n",
            "\n",
            "📊 Folder distribution:\n",
            "Counter({'wp1111': 238, 'ic1111': 123, 'dl': 48, 'bg_au': 38, 'tessi': 36, 'lw': 20, 'mj_au': 20, 'sk_au': 17, 'jc_au': 17, 'ts_au': 15, 'tp_au': 6})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 578/578 [25:28<00:00,  2.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Feature extraction complete. Saved as full_features_combined.csv\n",
            "\n",
            "📊 Label Distribution:\n",
            "label\n",
            "Parkinson    361\n",
            "Healthy      217\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Dropping columns with ALL NaN values: ['jitter', 'shimmer', 'hnr']\n",
            "\n",
            "Label mapping: {np.int64(0): 'Healthy', np.int64(1): 'Parkinson'}\n",
            "Label counts: {1: np.int64(361), 0: np.int64(217)}\n",
            "✅ PCA completed. Preprocessing pipeline saved.\n",
            "\n",
            "Logistic Accuracy: 0.9828\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.98      0.98      0.98        44\n",
            "   Parkinson       0.99      0.99      0.99        72\n",
            "\n",
            "    accuracy                           0.98       116\n",
            "   macro avg       0.98      0.98      0.98       116\n",
            "weighted avg       0.98      0.98      0.98       116\n",
            "\n",
            "\n",
            "SVM Accuracy: 0.9569\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.91      0.98      0.95        44\n",
            "   Parkinson       0.99      0.94      0.96        72\n",
            "\n",
            "    accuracy                           0.96       116\n",
            "   macro avg       0.95      0.96      0.95       116\n",
            "weighted avg       0.96      0.96      0.96       116\n",
            "\n",
            "\n",
            "RandomForest Accuracy: 0.9483\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.95      0.91      0.93        44\n",
            "   Parkinson       0.95      0.97      0.96        72\n",
            "\n",
            "    accuracy                           0.95       116\n",
            "   macro avg       0.95      0.94      0.94       116\n",
            "weighted avg       0.95      0.95      0.95       116\n",
            "\n",
            "\n",
            "GradientBoosting Accuracy: 0.9310\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.93      0.89      0.91        44\n",
            "   Parkinson       0.93      0.96      0.95        72\n",
            "\n",
            "    accuracy                           0.93       116\n",
            "   macro avg       0.93      0.92      0.93       116\n",
            "weighted avg       0.93      0.93      0.93       116\n",
            "\n",
            "\n",
            "ExtraTrees Accuracy: 0.9655\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.98      0.93      0.95        44\n",
            "   Parkinson       0.96      0.99      0.97        72\n",
            "\n",
            "    accuracy                           0.97       116\n",
            "   macro avg       0.97      0.96      0.96       116\n",
            "weighted avg       0.97      0.97      0.97       116\n",
            "\n",
            "\n",
            "🏆 Best ML Model: Logistic (0.9828) saved successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.6552"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.6965 - loss: 0.6190 - val_accuracy: 0.8065 - val_loss: 0.5056\n",
            "Epoch 2/30\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7812 - loss: 0.5414"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8726 - loss: 0.4515 - val_accuracy: 0.8602 - val_loss: 0.3746\n",
            "Epoch 3/30\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9062 - loss: 0.4441"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8889 - loss: 0.3557 - val_accuracy: 0.8817 - val_loss: 0.2973\n",
            "Epoch 4/30\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9688 - loss: 0.2734"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9133 - loss: 0.2947 - val_accuracy: 0.9032 - val_loss: 0.2430\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9295 - loss: 0.2368 - val_accuracy: 0.9032 - val_loss: 0.2092\n",
            "Epoch 6/30\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1508"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9485 - loss: 0.2041 - val_accuracy: 0.9247 - val_loss: 0.1703\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9431 - loss: 0.1980 - val_accuracy: 0.9140 - val_loss: 0.1865\n",
            "Epoch 8/30\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9688 - loss: 0.0902"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9458 - loss: 0.1575 - val_accuracy: 0.9570 - val_loss: 0.1411\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.1684 - val_accuracy: 0.9570 - val_loss: 0.1318\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9621 - loss: 0.1553 - val_accuracy: 0.9140 - val_loss: 0.1779\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9621 - loss: 0.1306 - val_accuracy: 0.9570 - val_loss: 0.1230\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9729 - loss: 0.1170 - val_accuracy: 0.9570 - val_loss: 0.1163\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9593 - loss: 0.1121 - val_accuracy: 0.9570 - val_loss: 0.1164\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9648 - loss: 0.1269 - val_accuracy: 0.9247 - val_loss: 0.1489\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9648 - loss: 0.1120 - val_accuracy: 0.9355 - val_loss: 0.1397\n",
            "Epoch 16/30\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0871"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.0918 - val_accuracy: 0.9677 - val_loss: 0.1028\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0772 - val_accuracy: 0.9570 - val_loss: 0.1242\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9837 - loss: 0.0795 - val_accuracy: 0.9677 - val_loss: 0.1155\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9702 - loss: 0.0719 - val_accuracy: 0.9677 - val_loss: 0.1199\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9675 - loss: 0.0790 - val_accuracy: 0.9462 - val_loss: 0.1379\n",
            "Epoch 21/30\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8750 - loss: 0.2765"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9783 - loss: 0.0776 - val_accuracy: 0.9892 - val_loss: 0.0873\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9864 - loss: 0.0697 - val_accuracy: 0.9677 - val_loss: 0.1187\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.0685 - val_accuracy: 0.9785 - val_loss: 0.0889\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9783 - loss: 0.0741 - val_accuracy: 0.9247 - val_loss: 0.1844\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0499 - val_accuracy: 0.9785 - val_loss: 0.0833\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0509 - val_accuracy: 0.9462 - val_loss: 0.1517\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0422 - val_accuracy: 0.9677 - val_loss: 0.1223\n",
            "Epoch 28/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9810 - loss: 0.0632 - val_accuracy: 0.9677 - val_loss: 0.1364\n",
            "Epoch 29/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9892 - loss: 0.0486 - val_accuracy: 0.9677 - val_loss: 0.1199\n",
            "Epoch 30/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9892 - loss: 0.0468 - val_accuracy: 0.9677 - val_loss: 0.1144\n",
            "CNN Test Accuracy: 0.9655\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6196 - loss: 0.6872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.6260 - loss: 0.6849 - val_accuracy: 0.6129 - val_loss: 0.6710\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6314 - loss: 0.6619 - val_accuracy: 0.6129 - val_loss: 0.6316\n",
            "Epoch 3/30\n",
            "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6357 - loss: 0.6325 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6341 - loss: 0.6368 - val_accuracy: 0.6667 - val_loss: 0.6106\n",
            "Epoch 4/30\n",
            "\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6335 - loss: 0.6301 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6612 - loss: 0.6239 - val_accuracy: 0.6989 - val_loss: 0.6008\n",
            "Epoch 5/30\n",
            "\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6637 - loss: 0.6037  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6694 - loss: 0.6074 - val_accuracy: 0.7419 - val_loss: 0.5768\n",
            "LSTM Test Accuracy: 0.6121\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 849ms/step - accuracy: 0.5625 - loss: 0.6432"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7724 - loss: 0.4867 - val_accuracy: 0.9032 - val_loss: 0.2516\n",
            "Epoch 2/30\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8438 - loss: 0.4973"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9079 - loss: 0.2830 - val_accuracy: 0.9677 - val_loss: 0.1626\n",
            "Epoch 3/30\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8750 - loss: 0.2752"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9295 - loss: 0.2039 - val_accuracy: 0.9785 - val_loss: 0.1257\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9648 - loss: 0.1474 - val_accuracy: 0.9677 - val_loss: 0.1128\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9593 - loss: 0.1202 - val_accuracy: 0.9677 - val_loss: 0.1019\n",
            "MLP Test Accuracy: 0.8190\n",
            "\n",
            "🏆 Best Deep Learning Model Accuracy: 0.9655\n",
            "✅ All best models and preprocessing pipeline saved successfully.\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# 1. SETUP & INSTALLS\n",
        "# ============================================\n",
        "!pip install librosa soundfile pandas scipy scikit-learn matplotlib tqdm torch torchvision transformers keras tensorflow pywavelets nolds parselmouth kymatio joblib --quiet\n",
        "\n",
        "import os, numpy as np, pandas as pd, librosa, torch, pywt, nolds, joblib\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
        "from kymatio import Scattering1D\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, LSTM, MaxPooling1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import parselmouth\n",
        "from parselmouth.praat import call as praat_call\n",
        "from collections import Counter\n",
        "\n",
        "# ============================================\n",
        "# 2. DEVICE & WAV2VEC2 LOADING\n",
        "# ============================================\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Running on:\", DEVICE)\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "wav2vec_model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\").to(DEVICE)\n",
        "\n",
        "# ============================================\n",
        "# 3. FEATURE EXTRACTION FUNCTIONS\n",
        "# ============================================\n",
        "def load_trim(path, sr=16000):\n",
        "    y, s = librosa.load(path, sr=sr)\n",
        "    y, _ = librosa.effects.trim(y, top_db=30)\n",
        "    return y, s\n",
        "\n",
        "def classical_feats(path):\n",
        "    try:\n",
        "        snd = parselmouth.Sound(path)\n",
        "        pp = praat_call(snd, \"To PointProcess (periodic, cc)\", 75, 500)\n",
        "        jitter = praat_call(pp, \"Get jitter (local)\", 0, 0, 75, 500, 1.3)\n",
        "        shimmer = praat_call([snd, pp], \"Get shimmer (local)\", 0, 0, 75, 500, 1.3, 1.6)\n",
        "        hnr = praat_call(snd, \"Get harmonics-to-noise ratio\", 0, 0)\n",
        "        return {\"jitter\": jitter, \"shimmer\": shimmer, \"hnr\": hnr}\n",
        "    except Exception:\n",
        "        return {\"jitter\": np.nan, \"shimmer\": np.nan, \"hnr\": np.nan}\n",
        "\n",
        "def nonlinear_feats(y):\n",
        "    def perm_entropy(sig):\n",
        "        order, delay = 3, 1\n",
        "        patterns, n = {}, len(sig)\n",
        "        for i in range(n - (order - 1) * delay):\n",
        "            ranks = tuple(np.argsort(sig[i:i + order * delay:delay]))\n",
        "            patterns[ranks] = patterns.get(ranks, 0) + 1\n",
        "        ps = np.array(list(patterns.values()), dtype=float)\n",
        "        ps /= ps.sum() + 1e-12\n",
        "        return -np.sum(ps * np.log2(ps + 1e-12))\n",
        "    try:\n",
        "        y_ds = librosa.resample(y, orig_sr=16000, target_sr=1000)\n",
        "        return {\n",
        "            \"hurst\": nolds.hurst_rs(y_ds),\n",
        "            \"lyapunov\": nolds.lyap_r(y_ds),\n",
        "            \"perm_entropy\": perm_entropy(y_ds)\n",
        "        }\n",
        "    except Exception:\n",
        "        return {\"hurst\": np.nan, \"lyapunov\": np.nan, \"perm_entropy\": np.nan}\n",
        "\n",
        "def wavelet_feats(y):\n",
        "    try:\n",
        "        coeffs = pywt.wavedec(y, 'db4', level=5)\n",
        "        energy = [np.sum(c**2) for c in coeffs]\n",
        "        total = sum(energy) + 1e-12\n",
        "        return {f\"wavelet_{i}_ratio\": energy[i] / total for i in range(len(energy))}\n",
        "    except Exception:\n",
        "        return {f\"wavelet_{i}_ratio\": np.nan for i in range(6)}\n",
        "\n",
        "def scattering_feats(y):\n",
        "    try:\n",
        "        N = 2 ** int(np.ceil(np.log2(len(y))))\n",
        "        y_pad = np.zeros(N)\n",
        "        y_pad[:len(y)] = y\n",
        "        scatter = Scattering1D(J=6, shape=N, Q=8)\n",
        "        Sx = scatter(torch.from_numpy(y_pad).unsqueeze(0).float())\n",
        "        Sx = Sx.squeeze(0).numpy() if hasattr(Sx, \"numpy\") else np.squeeze(Sx, axis=0)\n",
        "        return {f\"scat_mean_{i}\": float(np.mean(Sx[i])) for i in range(min(30, Sx.shape[0]))}\n",
        "    except Exception:\n",
        "        return {f\"scat_mean_{i}\": np.nan for i in range(30)}\n",
        "\n",
        "def wav2vec2_feats(y, sr):\n",
        "    try:\n",
        "        inputs = processor(y, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
        "        with torch.no_grad():\n",
        "            emb = wav2vec_model(inputs.input_values.to(DEVICE)).last_hidden_state.squeeze(0).cpu().numpy()\n",
        "        return {\"wav2vec_mean\": np.mean(emb), \"wav2vec_std\": np.std(emb)}\n",
        "    except Exception:\n",
        "        return {\"wav2vec_mean\": np.nan, \"wav2vec_std\": np.nan}\n",
        "\n",
        "# ============================================\n",
        "# 4. LOAD DATASET\n",
        "# ============================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Colab Notebooks/denoised-speech-dataset\"\n",
        "samples = [os.path.join(r, f) for r, _, fs in os.walk(DATASET_PATH) for f in fs if f.lower().endswith(\".wav\")]\n",
        "print(f\"Found {len(samples)} .wav files\\n\")\n",
        "\n",
        "# ✅ Print first 30 file paths for inspection\n",
        "print(\"📂 First 30 files in dataset:\")\n",
        "for f in samples[:30]:\n",
        "    print(f)\n",
        "\n",
        "# ============================================\n",
        "# 4A. DEBUGGING: FILE EXISTENCE CHECK\n",
        "# ============================================\n",
        "missing_files = [f for f in samples if not os.path.exists(f)]\n",
        "if missing_files:\n",
        "    print(f\"\\n❌ Missing files detected ({len(missing_files)}):\")\n",
        "    print(missing_files[:20])\n",
        "else:\n",
        "    print(\"\\n✅ All listed files exist.\")\n",
        "\n",
        "# ============================================\n",
        "# 4B. DEBUGGING: LABEL PREVIEW\n",
        "# ============================================\n",
        "folder_names = [os.path.basename(os.path.dirname(f)).lower() for f in samples]\n",
        "print(\"\\n📊 Folder distribution:\")\n",
        "print(Counter(folder_names))\n",
        "\n",
        "# ============================================\n",
        "# 5. FEATURE EXTRACTION PIPELINE\n",
        "# ============================================\n",
        "rows = []\n",
        "for file in tqdm(samples, desc=\"Extracting features\"):\n",
        "    try:\n",
        "        if not os.path.exists(file):\n",
        "            print(\"Error: File missing:\", file)\n",
        "            continue\n",
        "        y, sr = load_trim(file)\n",
        "        feats = {}\n",
        "        feats.update(classical_feats(file))\n",
        "        feats.update(nonlinear_feats(y))\n",
        "        feats.update(wavelet_feats(y))\n",
        "        feats.update(scattering_feats(y))\n",
        "        feats.update(wav2vec2_feats(y, sr))\n",
        "\n",
        "        folder = os.path.basename(os.path.dirname(file)).lower()\n",
        "\n",
        "        # ✅ UPDATED LABEL MAPPING\n",
        "        if folder in [\"wp1111\", \"ic1111\"]:\n",
        "            feats[\"label\"] = \"Parkinson\"\n",
        "        elif folder in [\"dl\", \"lw\", \"tessi\", \"bg_au\", \"mj_au\", \"sk_au\", \"jc_au\", \"ts_au\", \"tp_au\"]:\n",
        "            feats[\"label\"] = \"Healthy\"\n",
        "        else:\n",
        "            print(f\"⚠️ Unknown label for file: {file}\")\n",
        "            continue\n",
        "\n",
        "        feats[\"filename\"] = os.path.basename(file)\n",
        "        rows.append(feats)\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", file, e)\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "if df.empty:\n",
        "    raise ValueError(\"❌ No valid samples extracted! Check label mapping and file paths.\")\n",
        "else:\n",
        "    df.to_csv(\"full_features_combined.csv\", index=False)\n",
        "    print(\"\\n✅ Feature extraction complete. Saved as full_features_combined.csv\")\n",
        "    print(\"\\n📊 Label Distribution:\")\n",
        "    print(df[\"label\"].value_counts())\n",
        "\n",
        "# ============================================\n",
        "# 6. PREPROCESSING: IMPUTE + SCALE + PCA\n",
        "# ============================================\n",
        "X = df.drop([\"filename\", \"label\"], axis=1)\n",
        "y = df[\"label\"]\n",
        "\n",
        "drop_cols = X.columns[X.isna().all()].tolist()\n",
        "if drop_cols:\n",
        "    print(f\"\\nDropping columns with ALL NaN values: {drop_cols}\")\n",
        "    X = X.drop(columns=drop_cols)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "label_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
        "print(\"\\nLabel mapping:\", label_mapping)\n",
        "print(\"Label counts:\", dict(pd.Series(y).value_counts()))\n",
        "\n",
        "if len(np.unique(y)) < 2:\n",
        "    raise ValueError(\"❌ Only one class found. Check file naming or label extraction.\")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=0.95))\n",
        "])\n",
        "X_pca = pipeline.fit_transform(X)\n",
        "joblib.dump(pipeline, \"preprocessing_pipeline.joblib\")\n",
        "print(\"✅ PCA completed. Preprocessing pipeline saved.\")\n",
        "\n",
        "# ============================================\n",
        "# 7. CLASSICAL ML MODELS\n",
        "# ============================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "models = {\n",
        "    \"Logistic\": LogisticRegression(max_iter=1000),\n",
        "    \"SVM\": SVC(kernel='rbf', probability=True),\n",
        "    \"RandomForest\": RandomForestClassifier(200),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(),\n",
        "    \"ExtraTrees\": ExtraTreesClassifier()\n",
        "}\n",
        "\n",
        "best_model_name, best_model, best_acc = None, None, 0.0\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    print(f\"\\n{name} Accuracy: {acc:.4f}\")\n",
        "    print(classification_report(y_test, preds, target_names=le.classes_))\n",
        "    if acc > best_acc:\n",
        "        best_acc, best_model_name, best_model = acc, name, model\n",
        "\n",
        "joblib.dump(best_model, f\"best_ML_model_{best_model_name}.joblib\")\n",
        "print(f\"\\n🏆 Best ML Model: {best_model_name} ({best_acc:.4f}) saved successfully!\")\n",
        "\n",
        "# ============================================\n",
        "# 8. DEEP LEARNING MODELS (CNN / LSTM / MLP)\n",
        "# ============================================\n",
        "X_dl = np.expand_dims(X_pca, axis=2)\n",
        "y_dl = tf.keras.utils.to_categorical(y)\n",
        "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_dl, y_dl, test_size=0.2, random_state=42)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "def build_and_train(model, name, X_train, y_train, X_test, y_test):\n",
        "    checkpoint = ModelCheckpoint(f\"best_DL_model_{name}.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "    model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stop, checkpoint], verbose=1)\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"{name} Test Accuracy: {acc:.4f}\")\n",
        "    return acc\n",
        "\n",
        "# CNN\n",
        "cnn = Sequential([\n",
        "    Conv1D(64, 3, activation='relu', input_shape=(X_dl.shape[1], 1)),\n",
        "    MaxPooling1D(2),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(y_dl.shape[1], activation='softmax')\n",
        "])\n",
        "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_acc = build_and_train(cnn, \"CNN\", X_train_dl, y_train_dl, X_test_dl, y_test_dl)\n",
        "\n",
        "# LSTM\n",
        "lstm = Sequential([\n",
        "    LSTM(64, input_shape=(X_dl.shape[1], 1), return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(y_dl.shape[1], activation='softmax')\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "lstm_acc = build_and_train(lstm, \"LSTM\", X_train_dl, y_train_dl, X_test_dl, y_test_dl)\n",
        "\n",
        "# MLP\n",
        "mlp = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_dl.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(y_dl.shape[1], activation='softmax')\n",
        "])\n",
        "mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "mlp_acc = build_and_train(\n",
        "    mlp, \"MLP\",\n",
        "    X_train_dl.reshape(len(X_train_dl), -1), y_train_dl,\n",
        "    X_test_dl.reshape(len(X_test_dl), -1), y_test_dl\n",
        ")\n",
        "\n",
        "best_dl_acc = max(cnn_acc, lstm_acc, mlp_acc)\n",
        "print(f\"\\n🏆 Best Deep Learning Model Accuracy: {best_dl_acc:.4f}\")\n",
        "print(\"✅ All best models and preprocessing pipeline saved successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}